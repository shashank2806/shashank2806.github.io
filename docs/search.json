[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m always looking for opportunities to work on exciting projects. I’m currently open to part-time and full-time positions, as well as contract work. Let’s make something great, together."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello World! I am Shashank Shekhar",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     GitHub\n  \n  \n    \n     Medium\n  \n  \n    \n     Twitter\n  \n  \n    \n     Resume\n  \n  \n    \n     Email\n  \n\n      \nI am working as Data Scientist with 3+ years of experience. I have led several Deep learning based Vision & NLP Projects. I am well versed on developing and deploying ML solutions on Azure cloud.\nRead more about me here."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\nPython\n\n\n\n\nTheory along with Python code implementation on one of the most essestial algorithm of Machine Learning\n\n\n\n\n\n\nNov 27, 2022\n\n\n6 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAzure\n\n\nFlask\n\n\nAPI\n\n\n\n\nIn this blog, I am going to show how to deploy a Machine Learning API on Azure App Service (Web App).\n\n\n\n\n\n\nNov 20, 2022\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2022\n\n\n0 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is start of my bloging journey. I will writing about Deep Learning and this assciated with it. The topics I would like to write about in near future are - Computer Vision, NLP, Machine Learning on Azure Cloud, Deployment of ML Application on Azure Cloud, MLOps.\nWith this I am also takaing a 12-Week Blog Challenge, where ober the course of next 12 Weeks I will be writing - (atleast)1 Blog a week."
  },
  {
    "objectID": "posts/linear-regression/Linear_Regression.html",
    "href": "posts/linear-regression/Linear_Regression.html",
    "title": "Linear Regression - A Deep Dive!",
    "section": "",
    "text": "By the end of this blog you will bw able to understand:\n\nWhat is Regression and classification?\nDifference between Linear Regression and Non-Linear Regression.\nHyothesis(model) of Linear Regression\nCost function\nGradient Descent\nHow to code all these equation and algorithm in Python?\n\n\n\nRegression vs Classification\nIn Machine Learning, If the output variable has continous range, and we have to find the relationship between the the input and output variable(s). This is called Regression. Examples include - House Price, Salary, etc\nIn contrast, if the the output has descrete range. It is then called Classification. Examples include - Cat vs Dog, Spam/Not Spam, etc\nThese regresssion models can be used for both Inference and Prediction.\nIn this blog we are focused to get Prediction using Regression.\n\n\nRegression\nRegression in itself can be of multiple types - Linear and Non-Linear Regression.\nLinear Regression - When the model relates the input(independent) and output(dependent) varibale in straight line. Simple Linear Regression is subset of the prior, when there is only single input variable is present.\nNon-Linear Regression - When the model relates the input and output varibale in curved line.\nI am thowing a lot of jargons here so let me clarify few things before moving forward.\n\nInput Variable/Independent Variable/Feature are used interchangibly. In ML context these are the values which we are going to have to make the Prediction. For example :- For House Price Prediction we need Size. Size is the Input/Feature.\nOutput Varibale/Dependent Varibale/Target are those values which we are need to predict. Price is the target in case of the last example.\n\n\n\nLinear Regression\nIn this blog we are going to implement Simple Linear Regression on a small dataset. The information about the dataset is given below.\n\n# Imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nWe are using a small dataset from here. This a data about Cricket Chirps Vs. Temperature. We will use linear regression to fit model.\n\n# loading data\ndata = pd.read_excel('slr02.xls', engine='xlrd')\n\n*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n\n\nNow we look into data we see there are two columns X and Y, were\nX = chirps/sec for the striped ground cricket\nY = temperature in degrees Fahrenheit\n\n# visualise data\ndata.head()\n\n\n\n\n\n  \n    \n      \n      X\n      Y\n    \n  \n  \n    \n      0\n      20.000000\n      88.599998\n    \n    \n      1\n      16.000000\n      71.599998\n    \n    \n      2\n      19.799999\n      93.300003\n    \n    \n      3\n      18.400000\n      84.300003\n    \n    \n      4\n      17.100000\n      80.599998\n    \n  \n\n\n\n\n\n# data we got are in pandas dataframe format\n# we need to cast it in numpy array for calulations\nX = np.array(data.X)\nY = np.array(data.Y)\n\n\n# Now we have two arrays. One containing input features and other array has output features\n# visualise casted data\nprint(X,Y)\nprint(\"Data points:\", len(X))\n\n[20.         16.         19.79999924 18.39999962 17.10000038 15.5\n 14.69999981 17.10000038 15.39999962 16.20000076 15.         17.20000076\n 16.         17.         14.39999962] [88.59999847 71.59999847 93.30000305 84.30000305 80.59999847 75.19999695\n 69.69999695 82.         69.40000153 83.30000305 79.59999847 82.59999847\n 80.59999847 83.5        76.30000305]\nData points: 15\n\n\n\n# function for plotting data points\ndef plot_points(X, Y, xlabel, ylabel):\n    \"\"\"Plot points given X and Y co-ordinates and labels them\"\"\"\n    plt.plot(X, Y, 'o')\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n\nThis is the scatter-plot visualization of the data we have used. On X-axis we have chirps/sec and on the Y-axis we have Temperature.\n\n# plot data points\nplot_points(X, Y, \"chirps/sec for the striped ground cricket\", \"temperature in degrees Fahrenheit\")\n\n\n\n\n\n\nLinear Regression hypothesis/model\nAs mentioned earlier in the definition, Linear Regression is a way to find relationship between the input varibale (chirps/sec) and output varibale (temperature) with the help of a straight line.\nOur main objective is to fit a straight line though these data points. As we can see the input and output are linearly dependent (as input varibale value increases/decrease, output variable value also tend to increase/decrease).\nObjective : To find a best fit straight line through data points\nBest fit implies that the distance between the points and line should be minimum.\n\nIn the figure, \\(d_1,d_2,d_3,...., d_n\\) represents the distance between the point and the line and our goal is to minimize the sum of these distances.\nHypothesis Function: A stright line can be represented like \\(h_{\\theta}(x)={\\theta}_0 + {\\theta}_1x\\). Where \\({\\theta}_0\\) is the intercept and \\({\\theta}_1\\) is the slope of the line. We have to find this \\({\\theta}_0\\) and \\({\\theta}_1\\)\n\nBefore moving forward, These are some conventions we have taken for varibale names and mathematical equations.\n\\(m\\) : number of training examples (m=15, in this case)\n\\(X\\) : input / features\n\\(Y\\) : output/ target\n\\(x^{(i)}, y^{(i)}\\) : \\(i^{th}\\) training data.\n\\({\\theta}_0\\) ,\\({\\theta}_1\\): Model Parameters / Weights\n\n# initialised random thetas\nnp.random.seed(2)\ntheta = np.random.rand(2,1)\n# hypothesis of model\ndef hypothesis(X, theta):\n    \"\"\"Predicts output feature given input feature and theta\"\"\"\n    return theta[0] + theta[1] * X\n\nLet’s plot the initial line to check how ot fits our data.\n\n# plots line of regression\ndef draw_line(theta, X):\n    \"\"\"Plot a line from slope and intercept\"\"\"\n    x_vals = X\n    y_vals = hypothesis(x_vals, theta)\n    plt.plot(x_vals, y_vals, '--')\n\nWe want to plot data points and line of regession on same plot to see if we are progressing as we train our model\n\n# plots points and lines\ndef draw_points_and_lines(X, Y, xlabel, ylabel, theta):\n    \"\"\"Draws lines and points\"\"\"\n    plot_points(X, Y, xlabel, ylabel)\n    draw_line(theta, X)\n\nNow without training our model let’s were the line of regression lies\n\n# draw line of regression without traing model\ndraw_points_and_lines(X, Y, \"chirps/sec for the striped ground cricket\", \"temperature in degrees Fahrenheit\", theta)\n\n\n\n\n\n\nCost Function\nCost function givies us measure of how much we are error the hypothesis is making? These errors are measured as mean of squared error( \\(d_1,d_2,d_3,...., d_n\\)) terms.\n\nWe will be using squared error cost function which is formulated as,\n\n\\(d_{i} = h_{\\theta}(x^{(i)}) - y^{(i)}\\)(error)\nerrors can be both postive and negetive in direction so, we sqaure this error term to make all the error terms positive(+ve).\n\\((d_{i})^2 = (h_{\\theta}(x^{(i)}) - y^{(i)})^2\\)(squared error)\nWe need to the line which minimizes the mean of these squared error terms.\nCost function - (Mean Sqaured Error) \\[J({{\\theta}_0, {\\theta}_1}) =  \\frac{1}{2m}\\sum_{i=0}^{i=n-1}(h_{\\theta}(x^{(i)}) - y^{(i)})^2\\]\nNote:- Mean Squared Error is divided by 2 beacuse it will later help when finding gradient of the function\nWe need to minimize this Cost function with respect to \\({\\theta}_0, {\\theta}_1\\). After optimization, it will give us the value of parameters(thetas) which in turn will give us the best fit line.\n\n# cost function\nm = len(X)\ndef cost(X, Y, theta):\n    \"\"\"Returns cost\"\"\"\n    return (1/(2*m)) * np.sum((hypothesis(X, theta) - Y) ** 2)\n\n\n# initial cost without trraining model\ncost(X, Y, theta)\n\n3154.8870744571304\n\n\nWe have now defined a Cost function which tells us how wrong we are from actual label(target). The less the cost - the better. Right now with just random value of theta we have attained a very gigh cost. We need to minimize it. In this blog we are going to use a technique called Gradient Descent for minimization of the cost function.\n\n\nGradient Descent / Model Training\nGradient Descent is the optimization algorithm used to finding the value of paramerter which minimizes the value of cost function. In our case we are minimizing MSE Cost function with the help of this algorithm.\nThis algorithm works by iteratively updating the values of the parameters(thetas) in the direction of the negative gradient of the cost function with respect to the parameters. This means that at each iteration, the parameters are updated in the direction that reduces the value of the cost function.\n\n\n\nRepresentation of Gradient Descent in 2D Plane(for simlification of understaing). Here Cost is just function for single theta. Steps are taken in the direction opposite to the gradient/slope. Learning rate decides the step size. In this image the gradient is +ve, hence the steps taken will be in negative direction.\n\n\nThe learning rate(denoted by alpha, \\(\\alpha\\)) is the one of the hyperparameter(parameter, for which the value needs to decided manually). We need to set learning rate very carefully, It decides the step size in the negative direction of the gradient(slope).\nA higher learning rate can lead to faster convergence, but can also make the algorithm more likely to overshoot the minimum. A lower learning rate can be more stable, but can also lead to slower convergence.\nTo make a analogy, We can think Gradient descent algorithm like - We are blindfolded and descesnding from a hill(cost function). We will take a step forward evaulate the slope(gradient) and then move according to that. When we will reach bottom of the hill, then the step in any direction will take us upward and thus we know that be have reaced bottom(convergence).\n\n\n\nGradeint Descent in 3D plane, extension of previous image in both parameter\n\n\n\n\n\nMathematical equation for Gradient descent, parameters need to be updated by finding slope of the cost function w.r.t each parameter.\n\n\n\n\n\nEquation if Gradient Descent - After finding the gradient of cost function w.r.t \\(\\theta_0 and \\theta_1\\)\n\n\n\n# minimize cost through gradient descent - Model training\ndef gradient_descent(X, Y, theta, alpha, steps):\n    for i in range(steps):\n        old_cost = cost(X, Y, theta)\n        grad0 = ((1/m) * np.sum(hypothesis(X, theta) - Y))\n        grad1 = ((1/m) * np.dot((hypothesis(X, theta) - Y), X))\n        temp0 = theta[0] - alpha * grad0\n        temp1 = theta[1] - alpha * grad1\n        theta[0] = temp0\n        theta[1] = temp1\n        new_cost = cost(X, Y, theta)\n        if i%10 == 0:    #print every 10th epoch\n            if new_cost > old_cost:\n                print(\"WARNING!!! COST INCREASING\")\n            else:\n                print(\"Cost Decresing\", new_cost)\n\n\n# train model of 150 iterations\ngradient_descent(X, Y, theta, alpha=0.0001, steps=200)\ntheta\n\nCost Decresing 2980.5693134787443\nCost Decresing 1689.4327589238676\nCost Decresing 959.3382749612664\nCost Decresing 546.4942831760693\nCost Decresing 313.0448146583842\nCost Decresing 181.03693810660252\nCost Decresing 106.39088282551906\nCost Decresing 64.18101546051345\nCost Decresing 40.31272552858337\nCost Decresing 26.815983067351162\nCost Decresing 19.184003183555753\nCost Decresing 14.868350028147061\nCost Decresing 12.427968518501714\nCost Decresing 11.047990290588316\nCost Decresing 10.267634588205215\nCost Decresing 9.826345333024406\nCost Decresing 9.576786793160268\nCost Decresing 9.435645548985352\nCost Decresing 9.35581065326909\nCost Decresing 9.310642443891272\n\n\narray([[0.72065763],\n       [4.73296698]])\n\n\nAfter training we can clearly see we have reduced cost, and the cost has converged at a a fixed place, training it furteher will not lead lower cost, thus we can stop the furter interations. We have now found those parameters which gave us minimized cost.\n\n# cost after traing model\ncost(X, Y, theta)\n\n9.287030172925407\n\n\n\n# value of theta after training \ntheta\n\narray([[0.72065763],\n       [4.73296698]])\n\n\n\n# regression line after traing model\ndraw_points_and_lines(X, Y, \"chirps/sec for the striped ground cricket\", \"temperature in degrees Fahrenheit\", theta)\n\n\n\n\nWe can clearly see we have fitted line to the points. Thus we have successfully used linear regression to train a model.\n\n\nPrediction/Inference\nNow that we have found the appropriate line of fit through thsese points. We can also use this line to infer values on input values(chirps/sec) which are not present in the training data.\n\n# Temprature when 19 chirps/sec\nx = np.array([19])\nprint(f\"Predicted temprature when ground cricket chips 19 times a sec is {hypothesis(x, theta)[0]} degrees Farenheight.\")\n\nPredicted temprature when ground cricket chips 19 times a sec is 90.64703016147293 degrees Farenheight."
  },
  {
    "objectID": "posts/deploy-on-web-app/index.html",
    "href": "posts/deploy-on-web-app/index.html",
    "title": "Deploy ML Application on Azure App Service",
    "section": "",
    "text": "How to create an Azure Web App\nDifference between Azure Web App and App Service.\nDeploy your API on the Azure Web App\nTest your deployment\nBonus: How to connect the front-end to the API running on Web App.\n\nPrerequisites:\n\nAn Flask/FastAPI API is running locally.\nPostman - for API Testing\nAzure Account (Obviously!)\n\nThis is my folder structure. Out of these files 3 are important for deployment.\n\napp.py - Code for API is present here\nres18_10.pth - PyTorch trained model\nrequirement.txt - contains the dependent packages.( If you don’t have this. You can get them doing pip freeze in the virtual environment)\n\nAll these files can be found here if want to look in more details Github repo: https://github.com/shashank2806/simple-classifier-demo\n\n\n\nFiles in the directory\n\n\n\nStep 0 : Test the API locally.\n\nTest the API in the virtual environment you have developed it. If you have not developed it in a virtual environment, I would strongly suggest that you create one and install all the dependencies into it using requirements.txt.\nTest it on postman.\n\nThis is my API running locally on postman, it has route named ‘/pred’ which takes images as from-data.\nThis is the response when I upload this image of the cat. The model predicts it is a cat, cool.\n\n\n\nInput image of cat\n\n\nAs I have tested the API on my machine. Now it is ready for deployment. \n\n\nStep - 1: Create Azure Resources\nI am now going to create an Azure web app. A web app is the quickest method to deploy your APIs on the cloud. It supports both code and docker containers. In this blog, we are focusing on deployment through code.\n\n\n\n\n\nCreate a web app on the Azure portal. Select the subscription and Resource Group. You need to give it a unique name. Select OS and your python version. In my case, I have selected 3.10. Select the region.\nNow we have to select a app service plan. Most people have confusion between web app and app service.(Even both terms are used interchangeably) App service is the hardware on which you web app is deployed. Single App service can host multiple web apps. Keep this in mind when selecting your app service plan. I am selecting B1 plan, which is capable enough to host this API.\n \nClick Review+Create\nThe web app is created. A URL is also assigned - https://pytorch-demo.azurewebsites.net/\nThis is the URL where the web app will be hosted, There is nothing there right now.\n\n\n\n\n\n\n\nStep 2: Push code to the Web App\n\nOn the Azure Portal, go to the Deployment centre and select local git as the deployment source. You will get the git clone path, and username and password in the Credentials tab. Tip: The username is just ${web app name}, in my case $pytorch-demo, Do not enter the full username provided. \nGo to the directory containing the code. You can also test it on my demo code. Clone the github repo using git clone https://github.com/shashank2806/simple-classifier-demo.git You need git to be initialised (git init) in the directory, and commit (git commit) the changes you want to be uploaded.\nAdd a new remote to push code. I had initially one remote(origin) pointing to my Github. I have added new remote named azure which connects to web app. Use git remote add <git-clone-uri> to add remote. \nNow push the code to Azure using - git push azure master \nNow wait for few minutes, you can see the logs on the screen. Wait until the deployment succeeds.\n\nVoila The deplyment to the cloud is done! Now we can test it on postman.\n\n\n\n\n\nGreat!! As you can see, We have deployed the API over the cloud, now anyone can access it. We just need to give the user Endpoint and Key.\n\n\nStep 3: Bonus- Connect it with the front-end.\nWe have deployed our backend API on the web app. As you may have noticed there is an index.html in the directory. This contains a very simple front-end. We can connect the back-end API to the front-end.\nThe index.html is hosted through GitHub Pages(free hosting). The the hosted URL is https://shashankshekhar.me/simple-classifier-demo/\nIf you look into index.html, You will find a JavaScript - Fetch is used for calling the API. (You can get the code snippet to connect with help of postman.)\n    var requestOptions = {\n        method: \"POST\",\n        body: formData,\n        redirect: \"follow\",\n    };\n\n    // Change endpoint here\n    fetch(\"https://pytorch-demo.azurewebsites.net/pred\", requestOptions)\nYou can make some minor changes on this front-end to tailor it to your need. I have changed the Endpoint URL to the web app.\nLet’s try with our cat image. On this front-end.\n Voila! We have got the result, The API is taking to the font-end, the request we are making on our web browser is going to our API and fetching the results from there.\nThe API might not be responsing by the time you are looking at this web page - I will delete the App Service later.\n\n\nFinal Words\nWe now know:\n\nHow to deploy your API on the Azure app service\nTest the API through Postman\nHow to connect it to the front end. (or how to communicate with the frontend engineer about your ML API. Give them, endpoints, routes and keys/schema)\n\nThis method will work in most cases, where there are not complex dependencies, sometimes, there are OS-based dependencies for which we will have to deploy through Docker.\nEnjoy. Happy Learning!!!"
  },
  {
    "objectID": "index.html#latest-blogs",
    "href": "index.html#latest-blogs",
    "title": "Hello World! I am Shashank Shekhar",
    "section": "Latest Blogs",
    "text": "Latest Blogs\nClick here to check out more blogs.\n\n\n\n\n  \n\n\n\n\nLinear Regression - A Deep Dive!\n\n\n\n\n\nTheory along with Python code implementation on one of the most essestial algorithm of Machine Learning\n\n\n\n\n\n\nNov 27, 2022\n\n\nShashank Shekhar\n\n\n\n\n\n\n  \n\n\n\n\nDeploy ML Application on Azure App Service\n\n\n\n\n\nIn this blog, I am going to show how to deploy a Machine Learning API on Azure App Service (Web App).\n\n\n\n\n\n\nNov 20, 2022\n\n\nShashank Shekhar\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2022\n\n\nShashank Shekhar\n\n\n\n\n\n\nNo matching items"
  }
]